+ 概述
&emsp;&emsp;Spark是基于内存计算的大数据并行框架，是一个快速高效的大数据计算平台，用于构建大型的、低延迟的数据分析程序。

> Spark有以下几个主要特点:
    >> `运行速度快`:Spark使用先进的DAG（Directed Acyclic Graph,有向无环图）计算引擎，以支持循环数据流和内存计算，由于其基于内存计算的特性,执行速度比Hadoop MapReduce快上百倍，即使是基于硬盘的执行速度也能快10倍；
    >> `易于使用`:SPark支持Scala、Python、Java、R语言进行编程，其简介的API设计使用户能轻松搭建并行程序。并且还可以通过Spark Shell进行交互式编程；
    >> `通用性`:Spark提供了完整而又强大的技术栈，包括SQL查询、流式计算、机器学习和图算法组件，这些组件可以无缝集成，以应对复杂的计算；
    >> `运行模式多样`:Spark可运行于独立的集群模式中，或者运用于Hadoop，也可运用于Amazon EC2等云平台,并且可以访问HDFS、Cassandra、HBase、Hive等多种数据源


&emsp;&emsp;Spark最大的特性就是将计算数据、中间结果都存储在内存中，大大减少了IO开销，因而Spark更适合于迭代运算比较多的机器学习领域。

+ Spark生态系统
&emsp;&emsp;Spark主要使用场景如下:
    + 复杂的批量数据处理;
    + 基于历史数据的交互式查询；
    + 基于实时数据流的数据处理；

    + Spark组件
