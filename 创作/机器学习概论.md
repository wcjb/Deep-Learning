![2016年5月AlphaGo3:0大胜柯洁](https://upload-images.jianshu.io/upload_images/147042-3f4a39037297f536.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)


## 什么是机器学习？

---

&emsp;&emsp;前些年AlphaGo与中韩围棋大师的世纪决战至今仍历历在目，AlpahGo的压倒性胜利象征着人类在机器学习领域取得的极大进步。那么什么是机器学习呢？它又有着怎样的魔力能让人类所创造的机器在围棋领域战胜它的造物主呢。
&emsp;&emsp;机器学习(Machine Learning)主要研究如何让计算机模拟或实现人类的行为。让计算机可以像人一样去学习新的知识，不断的提高自己能力。简而言之，就是计算机像人类婴儿一样，通过不断接受外界的信息，学习新的知识，最终像成人一样形成自己的知识体系，能不断提升自己。机器学习是人工智能的核心，其应用范围涉及人工智能的若干领域。
&emsp;&emsp;那么机器学习与传统的计算机工作模式有什么不同呢？传统的计算机想要完成一项任务需要人类编写一段指令，计算机在按照这段指令一步步执行，直到得出结果，完成任务。可以说，传统的计算机就是一台升级版的“计算器”，通过详尽的步骤一步步“计算”出最终的结果。而机器学习则不然，它只需接受数据，并使用人类赋予的“学习能力”的指令，并从数据中“学习”出最终的结果。而赋予计算机学习能力的指令就是人们经常提起的各种算法，其实质其实是“相关而非因果”的统计学思想。
&emsp;&emsp;经过以上讨论可以得出这样一个粗糙的结论，机器学习就是计算机接受数据，然后利用算法得到相关模型的过程，最终用得到的模型去解决相关问题。显而易见，数据是机器学习的基础，而算法才是机器学习的核心，只有通过算法，计算机才能不断利用数据不断提升自己的性能。

---

## 常见机器学习算法
---
> 机器学习就是计算机接受数据，然后利用人类编写的算法得到相关模型的过程。常见的机器学习算法有四种，分别是：
* 监督学习
&emsp;&emsp;监督学习是指机器学习中计算机接受到的数据提供数据特征和数据类别；通过学习具备一定的判断能力，能够进行预测，主要用于分类。常见的监督学习算法有：
  - K-近邻算法
  - 决策树
  -  朴素贝叶斯
  - Logistic回归
  - 支持向量机
  - AdaBoost算法
  - 线性回归
  - 局部加权线性回归
  - 树回归
    ··· ···

* 无监督学习
&emsp;&emsp;无监督学习是指机器学习中计算机接受到的数据只提供数据特征，不提供数据类别；通过学习具备归纳概括能力，发现事物内在本质，主要用于聚类及数据降维。常见的无监督算法有：
  - K-均值
  - Apriori
  - FP-Growth
   ... ...
* 半监督学习
&emsp;&emsp;无监督学习是指机器学习中计算机接受到的数据中有一部分既包含数据特征又包含数据类别，同时有一部分数据只包含数据特征，是监督学习与无监督学习的融合。半监督学习算法一般是在监督学习算法的基础上进行扩展，使之可对未标注的数据建模。
* 增强学习
&emsp;&emsp;增强学习又称强化学习是指在学习过程中，采取一定的策略，激励系统对每格策略作出反馈，最终形成合理的规划。增强学习是试错学习，由于没有指导信息，参与学习的机器要不断与环境进行交互，通过试错的方式来获得最佳策略。常见的增强学习算法有：
  - 动态规划
  - 马尔可夫决策过程
   ... ...
---
## 机器学习常用术语
> 数据集(Data Set):样本的集合，通常假设数据集中样本之间是相互独立的。
> 训练集(Training Set):数据集中用于训练模型的部分，为了提高及合理评估模型的泛化能力，通常只会取数据集中一部分当作训练集。
> 测试集(Test Set):数据集中用于测试、评估模型泛化能力的部分，测试集不会用在模型的训练部分。
> 交叉验证集(Cross-Validation Set,CV Set):比较特殊的数据集，用来调整模型具体参数

Note：训练集用来估计模型，交叉验证集用来确定网络结构或控制模型复杂程度的参数，而测试集则检验最终选择的最优模型的性能优劣（测试集粗调参数，交叉验证集细调参数，用于模型优化，测试集测试已经训练好模型的推广能力）。一般来说，训练集占总样本的50%，其它各占25%，三部分都是从样本中随机抽取。当样本总量较小时，需要进行一定调整，通常是留少部分做测试集，然后对剩余样本N采用k折交叉验证法：将样本打乱，然后均匀分成K份，轮流选择其中的K-1份，剩余的一份做验证，计算预测误差平方和，最后把k次的预测误差平方和再做平均作为选择最优模型结构的依据。特别的，当K取N时，就是留一法(Leave One Out)。
      